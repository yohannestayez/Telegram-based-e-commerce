{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been split into train, validation, and test sets.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def read_conll_file(file_path):\n",
    "    \"\"\"Read CoNLL formatted file and return a list of sentences.\"\"\"\n",
    "    sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentence = []\n",
    "        for line in f:\n",
    "            if line.strip():  # Non-empty line\n",
    "                sentence.append(line.strip())\n",
    "            else:  # Empty line indicates end of a sentence\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "        if sentence:  # Add last sentence if the file doesn't end with a new line\n",
    "            sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def split_data(sentences, train_ratio=0.8, val_ratio=0.1):\n",
    "    \"\"\"Split the dataset into training, validation, and test sets.\"\"\"\n",
    "    random.shuffle(sentences)  # Shuffle sentences for random distribution\n",
    "    total = len(sentences)\n",
    "    train_end = int(train_ratio * total)\n",
    "    val_end = train_end + int(val_ratio * total)\n",
    "    \n",
    "    train_set = sentences[:train_end]\n",
    "    val_set = sentences[train_end:val_end]\n",
    "    test_set = sentences[val_end:]\n",
    "\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def write_conll_file(sentences, file_path):\n",
    "    \"\"\"Write sentences to a CoNLL formatted file.\"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for sentence in sentences:\n",
    "            for line in sentence:\n",
    "                f.write(line + '\\n')\n",
    "            f.write('\\n')  # New line to separate sentences\n",
    "\n",
    "# File paths\n",
    "input_file_path = 'C:/Users/elbet/OneDrive/Desktop/Ten/week5/Telegram-based-e-commerce/labeled_data_conll.conll'  # Replace with your file path\n",
    "train_file_path = 'train_data.conll'\n",
    "val_file_path = 'val_data.conll'\n",
    "test_file_path = 'test_data.conll'\n",
    "\n",
    "# Read data\n",
    "sentences = read_conll_file(input_file_path)\n",
    "\n",
    "# Split data\n",
    "train_set, val_set, test_set = split_data(sentences)\n",
    "\n",
    "# Write to new files\n",
    "write_conll_file(train_set, train_file_path)\n",
    "write_conll_file(val_set, val_file_path)\n",
    "write_conll_file(test_set, test_file_path)\n",
    "\n",
    "print(\"Data has been split into train, validation, and test sets.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telegram_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
