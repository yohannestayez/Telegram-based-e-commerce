{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fashion tera</td>\n",
       "      <td>@Fashiontera</td>\n",
       "      <td>3964</td>\n",
       "      <td>„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è \\nCLASICO\\nüî∏üî∏üî∏üî∏üî∏üî∏\\nPrice  2200( No ...</td>\n",
       "      <td>2024-09-24 14:34:31+00:00</td>\n",
       "      <td>photos\\@Fashiontera_3964.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fashion tera</td>\n",
       "      <td>@Fashiontera</td>\n",
       "      <td>3962</td>\n",
       "      <td>„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è\\nPuma \\nMade in Vietnam \\nüî∏üî∏üî∏üî∏üî∏...</td>\n",
       "      <td>2024-09-18 15:26:06+00:00</td>\n",
       "      <td>photos\\@Fashiontera_3962.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fashion tera</td>\n",
       "      <td>@Fashiontera</td>\n",
       "      <td>3950</td>\n",
       "      <td>New year Discount \\nüåºüåºüåºüåºüåºüåºüåºüåºüåº\\n„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è \\nüî∏üî∏...</td>\n",
       "      <td>2024-09-08 16:08:15+00:00</td>\n",
       "      <td>photos\\@Fashiontera_3950.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fashion tera</td>\n",
       "      <td>@Fashiontera</td>\n",
       "      <td>3939</td>\n",
       "      <td>„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è \\nSkechers \\nMade in Vietnam \\nüî∏üî∏üî∏üî∏...</td>\n",
       "      <td>2024-09-08 15:45:52+00:00</td>\n",
       "      <td>photos\\@Fashiontera_3939.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Fashion tera</td>\n",
       "      <td>@Fashiontera</td>\n",
       "      <td>3915</td>\n",
       "      <td>„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è\\nReebok \\nMade in Vietnam \\nüî∏üî∏üî∏...</td>\n",
       "      <td>2024-09-01 19:38:25+00:00</td>\n",
       "      <td>photos\\@Fashiontera_3915.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel Title Channel Username    ID  \\\n",
       "2   Fashion tera     @Fashiontera  3964   \n",
       "4   Fashion tera     @Fashiontera  3962   \n",
       "8   Fashion tera     @Fashiontera  3950   \n",
       "19  Fashion tera     @Fashiontera  3939   \n",
       "31  Fashion tera     @Fashiontera  3915   \n",
       "\n",
       "                                              Message  \\\n",
       "2   „Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è \\nCLASICO\\nüî∏üî∏üî∏üî∏üî∏üî∏\\nPrice  2200( No ...   \n",
       "4   „Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è\\nPuma \\nMade in Vietnam \\nüî∏üî∏üî∏üî∏üî∏...   \n",
       "8   New year Discount \\nüåºüåºüåºüåºüåºüåºüåºüåºüåº\\n„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è \\nüî∏üî∏...   \n",
       "19  „Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è \\nSkechers \\nMade in Vietnam \\nüî∏üî∏üî∏üî∏...   \n",
       "31  „Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è\\nReebok \\nMade in Vietnam \\nüî∏üî∏üî∏...   \n",
       "\n",
       "                         Date                    Media Path  \n",
       "2   2024-09-24 14:34:31+00:00  photos\\@Fashiontera_3964.jpg  \n",
       "4   2024-09-18 15:26:06+00:00  photos\\@Fashiontera_3962.jpg  \n",
       "8   2024-09-08 16:08:15+00:00  photos\\@Fashiontera_3950.jpg  \n",
       "19  2024-09-08 15:45:52+00:00  photos\\@Fashiontera_3939.jpg  \n",
       "31  2024-09-01 19:38:25+00:00  photos\\@Fashiontera_3915.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/Administrator/Documents/kifiya/Week_5/telegram_data.csv')\n",
    "\n",
    "df = df.dropna(subset=['Message'])\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the tokenizer and model for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\miniconda3\\envs\\condaenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model for NER\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mbeukman/xlm-roberta-base-finetuned-amharic-finetuned-ner-amharic\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"mbeukman/xlm-roberta-base-finetuned-amharic-finetuned-ner-amharic\")\n",
    "\n",
    "# Set up NER pipeline\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fashion tera</td>\n",
       "      <td>@Fashiontera</td>\n",
       "      <td>3964</td>\n",
       "      <td>\\nCLASICO\\n\\nPrice  2200 No gift box\\nFree De...</td>\n",
       "      <td>2024-09-24 14:34:31+00:00</td>\n",
       "      <td>photos\\@Fashiontera_3964.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fashion tera</td>\n",
       "      <td>@Fashiontera</td>\n",
       "      <td>3962</td>\n",
       "      <td>\\nPuma \\nMade in Vietnam \\n\\nSize 404143\\nPric...</td>\n",
       "      <td>2024-09-18 15:26:06+00:00</td>\n",
       "      <td>photos\\@Fashiontera_3962.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fashion tera</td>\n",
       "      <td>@Fashiontera</td>\n",
       "      <td>3950</td>\n",
       "      <td>New year Discount \\n\\n \\n\\nInbox Hiwe5266\\n·àµ·àç·ä≠...</td>\n",
       "      <td>2024-09-08 16:08:15+00:00</td>\n",
       "      <td>photos\\@Fashiontera_3950.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fashion tera</td>\n",
       "      <td>@Fashiontera</td>\n",
       "      <td>3939</td>\n",
       "      <td>\\nSkechers \\nMade in Vietnam \\n\\nSize 4243\\nP...</td>\n",
       "      <td>2024-09-08 15:45:52+00:00</td>\n",
       "      <td>photos\\@Fashiontera_3939.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Fashion tera</td>\n",
       "      <td>@Fashiontera</td>\n",
       "      <td>3915</td>\n",
       "      <td>\\nReebok \\nMade in Vietnam \\n\\nSize 404142\\nPr...</td>\n",
       "      <td>2024-09-01 19:38:25+00:00</td>\n",
       "      <td>photos\\@Fashiontera_3915.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel Title Channel Username    ID  \\\n",
       "2   Fashion tera     @Fashiontera  3964   \n",
       "4   Fashion tera     @Fashiontera  3962   \n",
       "8   Fashion tera     @Fashiontera  3950   \n",
       "19  Fashion tera     @Fashiontera  3939   \n",
       "31  Fashion tera     @Fashiontera  3915   \n",
       "\n",
       "                                              Message  \\\n",
       "2    \\nCLASICO\\n\\nPrice  2200 No gift box\\nFree De...   \n",
       "4   \\nPuma \\nMade in Vietnam \\n\\nSize 404143\\nPric...   \n",
       "8   New year Discount \\n\\n \\n\\nInbox Hiwe5266\\n·àµ·àç·ä≠...   \n",
       "19   \\nSkechers \\nMade in Vietnam \\n\\nSize 4243\\nP...   \n",
       "31  \\nReebok \\nMade in Vietnam \\n\\nSize 404142\\nPr...   \n",
       "\n",
       "                         Date                    Media Path  \n",
       "2   2024-09-24 14:34:31+00:00  photos\\@Fashiontera_3964.jpg  \n",
       "4   2024-09-18 15:26:06+00:00  photos\\@Fashiontera_3962.jpg  \n",
       "8   2024-09-08 16:08:15+00:00  photos\\@Fashiontera_3950.jpg  \n",
       "19  2024-09-08 15:45:52+00:00  photos\\@Fashiontera_3939.jpg  \n",
       "31  2024-09-01 19:38:25+00:00  photos\\@Fashiontera_3915.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to clean the text (remove emojis, symbols, etc.)\n",
    "def remove_emoji(text):\n",
    "    if isinstance(text, str):\n",
    "        return emoji.replace_emoji(text, replace='')\n",
    "    return text\n",
    "\n",
    "def remove_symbols(text):\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r'[^A-Za-z0-9·àÄ-·çê\\s]+', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply cleaning functions to 'Message' column\n",
    "df['Message'] = df['Message'].apply(remove_emoji).apply(remove_symbols)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map NER model results to CoNLL format labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map NER model results to CoNLL format labels\n",
    "def map_ner_to_conll(ner_results, tokens):\n",
    "    labels = ['O'] * len(tokens)  # Initialize labels as 'O' (Outside)\n",
    "    \n",
    "    for entity in ner_results:\n",
    "        word = entity['word'].replace('##', '')  # Remove subword artifacts from NER results\n",
    "        entity_type = entity['entity']  # Extract entity type\n",
    "        \n",
    "        # Define mapping for NER entity types\n",
    "        label = 'O'  # Default label\n",
    "        if entity_type == 'B-LOC':\n",
    "            label = 'B-LOC'\n",
    "        elif entity_type == 'I-LOC':\n",
    "            label = 'I-LOC'\n",
    "        elif entity_type == 'B-ORG':\n",
    "            label = 'B-PRODUCT'\n",
    "        elif entity_type == 'I-ORG':\n",
    "            label = 'I-PRODUCT'\n",
    "        elif entity_type == 'B-MISC':\n",
    "            label = 'B-PRICE'\n",
    "        elif entity_type == 'I-MISC':\n",
    "            label = 'I-PRICE'\n",
    "        \n",
    "        # Apply NER labels to matching tokens\n",
    "        for i, token in enumerate(tokens):\n",
    "            if word in token:\n",
    "                labels[i] = label\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Custom labeling function to identify prices and locations\n",
    "def custom_label_prices_locations(tokens):\n",
    "    labels = ['O'] * len(tokens)  # Initialize labels as 'O'\n",
    "    \n",
    "    # Define price patterns and location names\n",
    "    price_patterns = [r'^\\d*(00|.*50)(\\.\\d{1,2})?$', 'ETB', '·ãã·åã', '\\$', '·â•·à≠', 'Birr']\n",
    "    \n",
    "    product_patterns=['sketchers', 'Nike', 'Adidas','Rebook','samsung','Samsung','Vans','Nikon', 'Nike','Puma',\n",
    "                      'Adidas','Lacosta', 'Rolex','New','Allstar','Vapor','Sketchers','FILA','CK','TRAZER',\n",
    "                      'Jordan','Womens','Human','Couple','Original','Victorias','BURBERRY','OFFER','Fila','2TB',\n",
    "                      'CLASICO','Men','Balenciaga','Shose','CASENT','NIKE','Nike','Airforce','ROLEX','LOUIS','CYBER',\n",
    "                      'Speed','speed','AIR','Air','Skacher','Time','All','Fitron','FITRON','EMPORIO','CK',\n",
    "                      'CHANEL','Skechers','Sketcher','NB','Old','old','OLD','FENDI','SPEED','BRAND','Brand',\n",
    "                      'BALENCIAGA','GUCCI','CHEKICH','GIORGIO','Jordan','JORDAN', 'Vest','European','Fur','VIGUER',\n",
    "                      'Quality', 'QUALITY','SVETSEON','Couple','COUPLE','High','HIGH','Under','ADIDAS','VANS','Sun',\n",
    "                      'Rolex','LEBRON','Lebron','Yezzy','ALEXANDER','XO','Jacket','55','HURACHE','Clark','Hermes','VM','RADO','Apple',\n",
    "                      'Fendi','Police','Champion','Gucci','Stan','Calvin','SWISH','SKMEL','FOR','Cr','Military','VEST','YEEZY','DIESEL','chekich']\n",
    "    \n",
    "    locations = ['Addis','Ababa', '·â¶·àå', '·àú·ä≠·à≤·äÆ', '·àà·â°', 'Mekelle', 'Adama', 'Gondar', '·àà·â°','·àò·ã≥·àÖ·äí·ãì·àà·àù', \n",
    "                 '·àò·åà·äì·äõ', '·ä†·â†·â£', '·àÄ·ã≠·àé·âΩ','·å¶·à≠', '·ãµ·à™·àù', '·â≥·ãà·à≠','205','·ä†·ã≤·àµ', '·âÅ·å•·à≠', \"·â¢·àÆ\", \"·çé·âÖ\", \"2·â∞·äõ\" ]\n",
    "    \n",
    "    # First, process the specific tokens you provided with custom labels\n",
    "    custom_tokens = {\n",
    "          \n",
    "        \"·ä†·ãµ·à´·àª\"  : \"B-LOC\",       # Beginning of a location\n",
    "        \"Price\": \"B-PRICE\",         #Beginning of a price\n",
    "        \"Prices\": \"B-PRICE\",       #Beginning of a price\n",
    "        \"Free\" : \"O\",\n",
    "        \"Delivery\":\"O\",\n",
    "        \"Inbox\" :\"O\",\n",
    "        \"Hiwe5266\": \"O\",\n",
    "        \"·àµ·àç·ä≠\":\"O\",\n",
    "        \"·çã·àΩ·äï\":\"O\",\n",
    "        \"·â∞·à´\":\"O\",\n",
    "        \"Fashion\":\"O\",\n",
    "        \"Tera\":\"O\",\n",
    "        \"New\" : \"O\",\n",
    "        \"year\" :\"O\",\n",
    "        \"Discount\": \"O\",\n",
    "        \"me\" : \"O\",\n",
    "        \"httpsvmtiktokcomZM2yHbMPH\" : \"O\",\n",
    "        \"contact\" : \"O\",\n",
    "        \"sold\" : \"O\",\n",
    "        \"out\" : \"O\",\n",
    "        \"Sold\" : \"O\",\n",
    "        \"Call\" : \"O\",\n",
    "        \"call\" : \"O\",\n",
    "        \"more\" : \"O\",\n",
    "        \"info\" : \"O\",\n",
    "        \"as\" : \"O\",\n",
    "        \"Anyone\" : \"O\",\n",
    "        \"who\" : \"O\",\n",
    "        \"want\" : \"O\",\n",
    "        \"new\" : \"O\",\n",
    "        \"Original\" : \"O\",\n",
    "        \"BIG\" : \"O\",\n",
    "        \"DISCOUNT\" : \"O\",\n",
    "        \"·â•·ãõ·âµ\" : \"O\",\n",
    "        \"·àà·àù·âµ·ãà·àµ·ã±\" : \"O\",\n",
    "        \"·àç·ã©\" : \"O\",\n",
    "        \"·âÖ·äì·àΩ\" : \"O\",\n",
    "        \"·ä†·àà·ãâ\" : \"O\",\n",
    "        \"·â£·àâ·â†·âµ\" : \"O\",\n",
    "        \"·ä•·äì·ã∞·à≠·à≥·àà·äï\" : \"O\",\n",
    "        \"·å´·àõ\" : \"O\",\n",
    "        \"·àà·àò·åç·ãõ·âµ\" : \"O\",\n",
    "        \"·àò·à≠·ä´·â∂\" : \"O\",\n",
    "        \"·ä•·ã®·àÑ·ã±\" : \"O\",\n",
    "        \"·ã∞·ä≠·àò·ãã·àç\" : \"O\",\n",
    "        \"·ä•·äï·åç·ã≤·ã´·ãç·àµ\" : \"O\",\n",
    "        \"·âª·äì·àã·âΩ·äï·äï\" : \"O\",\n",
    "        \"·â†·àò·âÄ·àã·âÄ·àà\" : \"O\",\n",
    "        \"·ã®·çà·àà·åâ·âµ·äï\" : \"O\",\n",
    "        \"·ã≠·ãò·ãô·äï\" : \"O\",\n",
    "        \"·â£·àâ·â†·âµ\" : \"O\",\n",
    "        \"·ä•·äì·àò·å£·àà·äï\" : \"O\",\n",
    "        \"httpstmejoinchatAAAAAEYRIOB5Tt7gKGGjA\" : \"O\",\n",
    "        \"Enkuan\": \"O\",\n",
    "        \"le\": \"O\",\n",
    "        \"berhan\": \"O\",\n",
    "        \"meswkelu\": \"O\",\n",
    "        \"beselam\": \"O\",\n",
    "        \"adersachu\": \"O\",\n",
    "               \n",
    "\n",
    "    }\n",
    " \n",
    "    # Apply labels based on the tokens\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Check if token is in the custom list\n",
    "        if token in custom_tokens:\n",
    "            labels[i] = custom_tokens[token]\n",
    "        # Check if token matches very long numbers (10 digits or more)\n",
    "        elif re.match(r'^\\d{10,}$', token):\n",
    "            labels[i] = 'O'  # Label long numbers as 'O'\n",
    "        # Label prices (e.g., numbers, ETB, Birr, $, etc.)\n",
    "        elif any(pro in token for pro in product_patterns):\n",
    "            labels[i] = 'B-PRODUCT'\n",
    "        elif any(re.match(pattern, token) for pattern in price_patterns):\n",
    "            labels[i] = 'I-PRICE'\n",
    "        # Label locations (predefined locations)\n",
    "        elif any(loc in token for loc in locations):\n",
    "            labels[i] = 'I-LOC'\n",
    "        # Label other tokens as I-PRODUCT\n",
    "        else:\n",
    "            labels[i] = 'I-PRODUCT'\n",
    "    \n",
    "    return labels \n",
    "\n",
    "# Function to combine both NER and custom labels\n",
    "def combine_labels(ner_labels, custom_labels):\n",
    "    final_labels = []\n",
    "    \n",
    "    for ner_label, custom_label in zip(ner_labels, custom_labels):\n",
    "        if ner_label != 'O':  # NER label takes precedence\n",
    "            final_labels.append(ner_label)\n",
    "        else:\n",
    "            final_labels.append(custom_label)  # Otherwise, use custom label\n",
    "    \n",
    "    return final_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process a message with both NER and custom methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to process a message with both NER and custom methods\n",
    "def process_message(message, nlp_pipeline):\n",
    "    tokens = re.findall(r'\\S+', message)  # Tokenize the message\n",
    "    \n",
    "    # Apply NER model\n",
    "    ner_results = nlp_pipeline(message)\n",
    "    ner_labels = map_ner_to_conll(ner_results, tokens)\n",
    "    \n",
    "    # Apply custom labeling\n",
    "    custom_labels = custom_label_prices_locations(tokens)\n",
    "    \n",
    "    # Combine both label sets\n",
    "    final_labels = combine_labels(ner_labels, custom_labels)\n",
    "    \n",
    "    # Return tokens with their combined labels\n",
    "    labeled_tokens = [f\"{token} {label}\" for token, label in zip(tokens, final_labels)]\n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Apply the combined processing to each message\n",
    "df['Labeled_Message'] = df['Message'].apply(lambda msg: process_message(msg, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       CLASICO B-PRODUCT\\nPrice B-PRICE\\n2200 I-PRICE...\n",
       "4       Puma B-PRODUCT\\nMade I-PRODUCT\\nin I-PRODUCT\\n...\n",
       "8       New O\\nyear O\\nDiscount O\\nInbox O\\nHiwe5266 O...\n",
       "19      Skechers B-PRODUCT\\nMade I-PRODUCT\\nin I-PRODU...\n",
       "31      Reebok I-PRODUCT\\nMade I-PRODUCT\\nin I-PRODUCT...\n",
       "                              ...                        \n",
       "2612                                        Sold O\\nout O\n",
       "2613    Nikon B-PRODUCT\\nD9 I-PRODUCT\\nDigital I-PRODU...\n",
       "2614    Vans B-PRODUCT\\nLeather I-PRODUCT\\nMade I-PROD...\n",
       "2615    Samsung B-PRODUCT\\nTV I-PRODUCT\\nCurved I-PROD...\n",
       "2616    Rebook B-PRODUCT\\nMade I-PRODUCT\\nin I-PRODUCT...\n",
       "Name: Labeled_Message, Length: 1920, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Labeled_Message'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the final labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled data saved to C:/Users/Administrator/Documents/kifiya/Week_5/labeled_data_conll.conll\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the final labeled data to a CoNLL-style file\n",
    "output_file_combined = 'C:/Users/Administrator/Documents/kifiya/Week_5/labeled_data_conll.conll'\n",
    "with open(output_file_combined, 'w', encoding='utf-8') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")\n",
    "\n",
    "\n",
    "print(f\"labeled data saved to {output_file_combined}\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
